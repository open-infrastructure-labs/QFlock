---
  debug: false
  benchmark:
    name: TPC-DS
    db-name: tpcds
    docker-name: qflock-spark-app
    tool-path: "../tpcds-kit/tools"
    tool-commandline: "./dsdgen -scale 1 -RNGSEED 42"
    file-extension: "dat"
    raw-data-path: "../data/tpcds-data"
    parquet-path: "hdfs://qflock-storage-dc1:9000/tpcds-parquet"
    # parquet-path: "webhdfs://qflock-storage:9870/tpcds-parquet"
    query-path: "queries/tpcds"
#    limit-rows: "1000"
    query-extension: "sql"
    query-exceptions: "2,5,43,59,13,48,24a,24b,75"
#    jdbc-path: "jdbc:hive2://qflock-dc2-spark:10001/tpcds;transportMode=http;httpPath=cliservice"
#    jdbc-path: "jdbc:hive2://qflock-dc2-spark:10000/tpcds;transportMode=binary;httpPath=cliservice"
#    jdbc-path: "jdbc:qflock://local-docker-host:1433/tpcds"
    jdbc-path: "jdbc:qflock://qflock-jdbc-dc2:1433/tpcds"
    docker-stats: "qflock-storage-dc1:tx_bytes:eth0,qflock-storage-dc2:tx_bytes:eth1,\
                   qflock-spark-dc1:rx_bytes:eth0,qflock-spark-dc1:rx_bytes:eth1"
  spark:
    master: local[4]
    hive-metastore: "qflock-storage-dc1"
    hive-metastore-ports: "default:9084"
    conf:
    - spark.driver.maxResultSize=2g
    - spark.driver.memory=2g
    - spark.executor.memory=2g
    - spark.sql.execution.arrow.enabled=true
    - spark.sql.catalogImplementation=hive
#    - spark.sql.hive.metastore.version=3.1.2
#    - spark.sql.hive.metastore.jars=path
#    - spark.sql.hive.metastore.jars.path=jars/*.jar
    - spark.sql.warehouse.dir=hdfs://qflock-storage-dc1:9000/user/hive/warehouse3
#    - spark.sql.extensions=com.github.qflock.FederationExtensions,
    - spark.sql.extensions=com.github.qflock.extensions.rules.QflockExtensions
    - spark.sql.cbo.enabled=true
    - spark.sql.statistics.histogram.enabled=true
#    - spark.sql.statistics.histogram.numBins=4096
#    - spark.sql.cbo.planStats.enabled=true
#    - spark.sql.cbo.joinReorder.enabled=true
#    - spark.sql.optimizer.excludedRules=org.apache.spark.sql.catalyst.optimizer.CostBasedJoinReorder
    - 'spark.driver.extraJavaOptions=-classpath /conf/:/opt/spark-3.2.1/jars/*: -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=172.23.0.3:5006'
#    packages:
#    - org.apache.spark:spark-hive_2.12:3.2.1
    jars:
    - /extensions/target/scala-2.12/qflock-extensions_2.12-0.1.0.jar
    - /qflock/jdbc/driver/target/thrift-jdbc-server-0.0.4-SNAPSHOT.jar

